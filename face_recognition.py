# -*- coding: utf-8 -*-
"""face-recognition.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cqjYURQnRoai_LWcrhXnsUB-GLsRWO19

# **Face Recognition in images**

**Face Identification:** Spotting a human face in an image <br>
**Face Recognition:** Determining which individual the face belongs to. 

In this project: we use the image recognition functionality in the 'face-recognition' python library

**Steps:** <br>
1) Capture the face encodings of Known images. <br>
2) Capture the face encodings of the Unknown images <br>
3) Compare the two and see if known image encodings are present in the images with unknown faces.
"""

#Install library
pip install face_recognition

#Library imports
import face_recognition
import cv2
import os
from google.colab.patches import cv2_imshow
import numpy as np

#Set Parameters
KNOWN_FACES_DIR = "known_faces"
UNKNOWN_FACES_DIR ="Unknown_faces"
TOLERANCE =0.6
FRAME_THICKNESS = 3
FONT_THICKNESS= 2
FONT = cv2.FONT_HERSHEY_SIMPLEX
MODEL ="cnn" #hog or cnn 
known_faces=[]
known_names=[]
showImages=[]
facial_features_list=[]

"""Read and Process Known Faces"""

#Reading known faces from known faces folders
for name in os.listdir(KNOWN_FACES_DIR):

  # Next we load every file of faces of known person
  for filename in os.listdir(f'{KNOWN_FACES_DIR}/{name}'):

    # Load an image
    image = face_recognition.load_image_file(f'{KNOWN_FACES_DIR}/{name}/{filename}')

    # Face encoding captures 128 points on the face and stores them in array
    # Always returns a list of found faces, for this purpose we take first face only (assuming one face per image as you can't be twice on one image)
    encoding = face_recognition.face_encodings(image)[0]

    # Append encodings and name
    known_faces.append(encoding)
    known_names.append(name)

"""Read and Process Unknown Faces"""

# Returns (R, G, B) from name for unique border color for an individual
def name_to_color(name):
  # Take 3 first letters, tolower()
  # lowercased character ord() value rage is 97 to 122, substract 97, multiply by 8
  color = [(ord(c.lower())-97)*8 for c in name[:3]]
  return color

def resize(image,window_height = 500):
    aspect_ratio = float(image.shape[1])/float(image.shape[0])
    window_width = window_height/aspect_ratio
    image = cv2.resize(image, (int(window_height),int(window_width)))
    return image

showImages=[]
# Now let's loop over a folder of faces we want to label
for filename in os.listdir(UNKNOWN_FACES_DIR):

  # Load image
  print(f'\nFilename {filename}', end='')
  image = face_recognition.load_image_file(f'{UNKNOWN_FACES_DIR}/{filename}')

  image = resize(image, 700)

  # Face Locations returns coordinates of points where the face is located in the image. 
  locations = face_recognition.face_locations(image, model=MODEL)

  # Now since we know locations, we can pass them to face_encodings as second argument
  # Without that it will search for faces once again slowing down whole process
  encodings = face_recognition.face_encodings(image, locations)

  # We passed our image through face_locations and face_encodings, so we can modify it
  # First we need to convert it from RGB to BGR because BGR is the standard color model used in cv2 for historical reasons
  image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)

  #Count the number of faces in the image
  print(f"\nThere are {len(encodings)}(s) faces in the image")

    #We now compare the new faces found to the known_faces        
  #It checks if the new unknown face matches any one of the three known faces images 
  for face_encoding, face_location in zip(encodings, locations):

    # We use compare_faces (but might use face_distance as well)
    # Returns array of True/False values in order of passed known_faces

    results = face_recognition.compare_faces(known_faces, face_encoding, TOLERANCE)
    print(results)

    # Since order is being preserved, we check if any face was found then grab index
    # then label (name) of first matching known face withing a tolerance
    match = None
    if True in results:  # If at least one is true, get a name of first of found labels
      match = known_names[results.index(True)]
      match=match.replace("_", " ")
      print(f' - {match} from {results}')

      # Each location contains positions in order: top, right, bottom, left
      top_left = (face_location[3], face_location[0])
      bottom_right = (face_location[1], face_location[2])

      # Get color by name using our fancy function
      color = name_to_color(match)

      # Paint frame
      cv2.rectangle(image, top_left, bottom_right, color, FRAME_THICKNESS)

      # Now we need smaller, filled frame below for a name
      # This time we use bottom in both corners - to start from bottom and move 50 pixels down
      top_left = (face_location[3], face_location[2])
      bottom_right = (face_location[1], face_location[2] + 22)

      # Paint frame
      cv2.rectangle(image, top_left, bottom_right, color, cv2.FILLED)

      # Wite a name
      cv2.putText(image, match, (face_location[3] + 10, face_location[2] + 15), FONT, 0.5, (200, 200, 200), FONT_THICKNESS)

      # Resize image 
      #image=cv2.resize(image, (int(image.shape[1]*0.8), int(image.shape[0]*0.8)))

  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)   
  # Show image
  showImages.append(image)

#Using Matplot lib for proper presentation of the images
from matplotlib import pyplot as plt

columns=4
rows= int(np.ceil(len(showImages)/columns))
for i in range(len(showImages)):
  plt.subplots(figsize=(25,25))
  plt.subplot(rows, columns, i+1)

  plt.imshow(showImages[i])
  plt.xticks([])
  plt.yticks([])
  plt.savefig("saved_images.jpg", bbox_inches='tight')